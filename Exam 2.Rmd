---
title: "Exam 2"
author: "First Last"
date: "11/01/2021"
output: html_document
---


# Instructions

a. Create a folder in your computer (a good place would be under Crim 250, Exams). 

b. Download the dataset from the Canvas website (sim.data.csv) onto that folder, and save your Exam 2.Rmd file in the same folder.

c. Data description: This dataset provides (simulated) data about 200 police departments in one year. It contains information about the funding received by the department as well as incidents of police brutality. Suppose this dataset (sim.data.csv) was collected by researchers to answer this question: **"Does having more funding in a police department lead to fewer incidents of police brutality?"**
d. Codebook:
- funds: How much funding the police department received in that year in millions of dollars.
- po.brut: How many incidents of police brutality were reported by the department that year.
- po.dept.code: Police department code

# Problem 1: EDA (10 points) 

Describe the dataset and variables. Perform exploratory data analysis for the two variables of interest: funds and po.brut.

```{r}
dat <- read.csv(file = 'sim.data.csv')
class(dat$funds)
class (dat$po.dept.code)
class (dat$po.brut)

table<-table (dat$funds,dat$po.brut)

```

```{{r, fig.width=4, fig.height=4}
x <- dat$funds 
y <- dat$po.brut
plot(x, y, main = "Scatterplot of Funding for Police Departments Vs. Number of Instances of Police Brutality",
     xlab = "Funding for Police Departments (in millions)", ylab = "Number of Instances of Police Brutality",
     pch = 19, frame = FALSE)
cor(x, y, method = c("pearson", "kendall", "spearman"))
abline(reg.output, col = "red", lwd=2) 

barplot(table, 
        main = "Barchart of Funding for Police Departments Vs. Number of Instances of Police Brutality",
        xlab = "Funding for Police Departments (in millions)", ylab = "Number of Instances of Police Brutality",
        legend.text = rownames(table),
        beside = FALSE)


```

__The data set, which observes the instances of police brutality across 200 police departments,  is comprised of 200 observations of 3 variables, the variables being funds, po. brut, and po.dept.code.  Funds is a quantitative variable with units millions of dollars, brut is a quantitative variable, and po.dept. code is an identifier variable. In terms of r, funds is a numeric variable while po.brut an po.dept.code are integers. Since I have two continuous, qualitative variables, I first created a table  since it is the most basic bivariate non-graphical technique of EDA, however it was difficult to contextualize the data with just the table. Therefore, I made a barchart and a scatter plot. The barchart was not as reliable in analyzing the data as the frequency of instances of police bruatity continued to fluctuate as the funding increased. However, the scatterplot suggested (with a very strong negative correlation) that the more funds a department receives, the less instances of police brutality occurs. In the steps below, I realize this conclusion I've made is not actually accurate. __


# Problem 2: Linear regression (30 points)

a. Perform a simple linear regression to answer the question of interest. To do this, name your linear model "reg.output" and write the summary of the regression by using "summary(reg.output)". 

```{r, eval=TRUE}
# Remember to remove eval=FALSE!!
reg.output <- lm(formula = po.brut ~ funds, data = dat)
summary(reg.output)
```

__According to the linear regression model, having more funding in the police departments does not lead to fewer instances of police bruatlity. The summary shows that the Pr(>|t|) value of <2e-16 is 0% statistically significant.__

b. Report the estimated coefficient, standard error, and p-value of the slope. Is the relationship between funds and incidents statistically significant? Explain.

__The estimated coefficient = -0.367099, the standard error = 0.004496, and the p value of the slope = <2e-16. According to the summary, the relationship between funds and incidents is not statistically significant. Typically, when the p value is less than or equal to the significance level (p = 0.05), we can reject the null hypothesis, meaning there is a definite consequential relationship between the two variables. The p value here was so low indicating that null hypothesis is very incompatible with the dta collected. This leads me to beleive that the two variables have too many other factors in play that a correlation between just funding and instances of police brutality would be oversimplifying the issue. .__

c. Draw a scatterplot of po.brut (y-axis) and funds (x-axis). Right below your plot command, use abline to draw the fitted regression line, like this:

# Remember to remove eval=FALSE!!

```{{r, fig.width=4, fig.height=4}
x <- dat$funds 
y <- dat$po.brut
plot(x, y, main = "Scatterplot of Funding for Police Departments Vs. Number of Instances of Police Brutality",
     xlab = "Funding for Police Departments (in millions)", ylab = "Number of Instances of Police Brutality",
     pch = 19, frame = FALSE)
cor(x, y, method = c("pearson", "kendall", "spearman"))
abline(reg.output, col = "red", lwd=2) 
```

Does the line look like a good fit? Why or why not?

__The line passes through most of the data points, especially in the center of the graph. Thus, it appears to be a good fit.__

d. Are the four assumptions of linear regression satisfied? To answer this, draw the relevant plots. (Write a maximum of one sentence per assumption.) If not, what might you try to do to improve this (if you had more time)?

```{r} 
install.packages("ggplot2",repos = "http://cran.us.r-project.org")
install.packages("ggfortify",repos = "http://cran.us.r-project.org")
library (ggplot2)
library(ggfortify)
autoplot(reg.output)
plot(reg.output, 1)
plot(reg.output, 3)
plot(reg.output, 2)
plot(reg.output, 5)
```

__The assumption of linearity is not satisfied because the residual plot shows a fitted pattern, as in the red line is not at all horizontal at zero. The assumption of homoscedasticity is not satisfied because there isn't a horizontal line with equally spread points since the variability of the residual points decreases, increases, decreases, and finally increases as the value of the fitted outcome variable increases, suggesting non-constant variances in the residuals errors (or heteroscedasticity).The assumption of normality is not satisfied because all the data points do not fall on the reference line. The assumption of independence is not satisfied because a great deal of the values are far beyond the Cook's distance lines, suggesting a high Cook's distance score.__

e. Answer the question of interest based on your analysis.

__Based on my analysis, none of the assumptions of a linear regression model were satisfied, thus why the linear regression model was not very useful. In fact, I was surprised with the results, but the failed assumptions explains why this model was not the best model to analze the data.__

# Problem 3: Data ethics (10 points)

Describe the dataset. Considering our lecture on data ethics, what concerns do you have about the dataset? Once you perform your analysis to answer the question of interest using this dataset, what concerns might you have about the results?

__I believe that there is not enough consideration of the racial biases within policing. The data only accounts for two distinct factors with no acknowledgement of several, oustanding factors such as location of the police departments, races of the individuals involved in the instances of police brutality, etc. The issue of police brutality is not merely an economic issue Essentially, the data set does not reflect the real social, racial, and economic implications of policing, creating an incomplete dataset and therefore weak conclusion.  .__
